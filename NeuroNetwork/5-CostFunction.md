# Cost function 损失函数

``阿扣``：阿特，还记得训练神经网络的目标其实是什么吗？

``阿特``：我记得好像是要找出最合适的权重(weights)，使得输出结果尽可能接近真实值。

``阿扣``：Hin 棒！你说的没错。说回到训练神经网络，我们需要在训练中及时了解训练效果如何，是不是朝着训练目标在一点点靠近。如果偏离目标，就说明训练模型可能在「犯错」，就要纠正过来。

``阿特``：那怎么知道模型是不是在「犯错」呢？

``阿扣``：我们会找一个度量标准。一个常见的度量方法是计算误差的平方和（SSE, sum of the squared errors）：

$$ E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum_i w_{ij}x^\mu_i)]^2 $$

``阿特``：你……欺负人 >.<

``阿扣``：别着急，我们来拆解这一坨是个什么东西。先看看各个字母的含义：

![](http://7xjpra.com1.z0.glb.clouddn.com/il_for_SSE-1.png)

这个等式里面，有三个求和项（就是这个翻转了 90° 的 M： $\sum$ ）。

最右边的求和项 $\sum_i w_{ij}x^\mu_i$ ，表示我们训练出来的权重 w 乘上输入值 x 得出的目标值 $\hat y$（也就是我们给数据打算的标签），然后用这些结果跟实际的数据中的 y 值做比较，看看偏差有多大。

现在你理解了最右边的求和项了吗？

``阿特``：大概意思是我们从数据中预测出来的 y ？

``阿扣``：没错，我们先把这一坨替换成 $\hat y$，简化一下公式：

$$
E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum_i w_{ij}x^\mu_i)]^2
\\
\downarrow
\\
E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - \hat y_j]^2
$$

``阿特``：世界清静多了~

``阿扣``：我们再来看右边这个求和项。j 表示有 j 个隐层节点，把每个节点的误差平方 $[y^\mu_j - \hat y_j]$ 计算出来。现在只剩下最后一个求和项了，它表示把 u 个输出节点的误差加起来。这样就得到了总体误差。
